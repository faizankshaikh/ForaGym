{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65105345",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/faizankshaikh/ForaGym/blob/main/examples/trial1_foragymSimple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "WEiHNbct33VM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEiHNbct33VM",
    "outputId": "750d83fa-5480-434d-d567-f8fe610a5cfb"
   },
   "outputs": [],
   "source": [
    "!git clone --quiet https://github.com/faizankshaikh/ForaGym.git\n",
    "%cd ForaGym\n",
    "!pip install -q -e .\n",
    "!pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7693b5ea-4e87-4149-aa8c-fa9d709e8c91",
   "metadata": {
    "id": "7693b5ea-4e87-4149-aa8c-fa9d709e8c91"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import foragym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314c8477-4e4c-40ac-a3b7-e26ac9f7d407",
   "metadata": {
    "id": "314c8477-4e4c-40ac-a3b7-e26ac9f7d407"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"foragym:foragym/ForaGym-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94752668-8c12-4795-93e7-7a80dd8c1342",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94752668-8c12-4795-93e7-7a80dd8c1342",
    "outputId": "2b042364-fb9b-47d3-ce35-54235e35dbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #1\n",
      "==========\n",
      "Initial state:-\n",
      "--Days left: 6\n",
      "--State of Field: [0 1 1 0 0]\n",
      "--Current life: 2\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 5\n",
      "--State of Field: [1 0 1 0 1]\n",
      "--Current life: 1\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: False\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 4\n",
      "--State of Field: [0 0 0 0 1]\n",
      "--Current life: 0\n",
      "--Type of Weather: Clear\n",
      "\n",
      "----------\n",
      "Episode #2\n",
      "==========\n",
      "Initial state:-\n",
      "--Days left: 6\n",
      "--State of Field: [1 0 0 0 1]\n",
      "--Current life: 3\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 5\n",
      "--State of Field: [0 0 1 1 0]\n",
      "--Current life: 2\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 4\n",
      "--State of Field: [0 0 1 0 1]\n",
      "--Current life: 1\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: False\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 3\n",
      "--State of Field: [1 1 1 1 1]\n",
      "--Current life: 0\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 2\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(f\"Episode #{episode+1}\")\n",
    "    print(\"=\" * 10)\n",
    "\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "\n",
    "    print(\"Initial state:-\")\n",
    "    env.render()\n",
    "    print()\n",
    "\n",
    "    while not done:\n",
    "        action = 0 #env.action_space.sample()\n",
    "        print(f\"Action to take: {env.ACTION_DICT[action]}\")\n",
    "        state, reward, done, info = env.step(action)\n",
    "        print(f'Chance to find food: {info[\"chance\"]:.2f}')\n",
    "        print(f\"Reward?: {reward}\")\n",
    "        print(f\"is Alive?: {not done}\")\n",
    "        print()\n",
    "        print(\"Current game state:-\")\n",
    "        env.render()\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4797aec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-3.50 +/- 1.74\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "episode_reward = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = 0 #env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "    episode_reward.append(total_reward)\n",
    "\n",
    "print(f\"mean_reward:{np.mean(episode_reward):.2f} +/- {np.std(episode_reward):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e5c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb731c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = env.NUM_STATES\n",
    "num_actions = env.NUM_ACTIONS\n",
    "\n",
    "V = np.zeros(num_states)\n",
    "optimal_policy = np.zeros([num_states, num_actions])\n",
    "\n",
    "for s in range(num_states):\n",
    "\tactions_s = np.zeros(num_actions)\n",
    "\tfor a in range(num_actions):\n",
    "\t\tfor transition_prob, next_state, reward, done in env.P[s][a]:\n",
    "\t\t\tactions_s[a] += reward + transition_prob * V[next_state]\n",
    "\tV[s] = actions_s.max()\n",
    "\toptimal_policy[s, np.argmax(actions_s)] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987742db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, pol in enumerate(optimal_policy):\n",
    "#     field, life_point, weather = env.decode(idx)\n",
    "#     print(f\"field: {field}/{env.NUM_FIELDS}, life_point: {life_point}, weather: {env.WEATHER_DICT[weather]}:- action: {env.ACTION_DICT[np.argmax(pol)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112304b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #1\n",
      "==========\n",
      "Initial state:-\n",
      "--Days left: 6\n",
      "--State of Field: [1 1 0 0 0]\n",
      "--Current life: 2\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "33\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.37\n",
      "Reward?: -2\n",
      "is Alive?: False\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 5\n",
      "--State of Field: [0 1 0 0 1]\n",
      "--Current life: 0\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "----------\n",
      "Episode #2\n",
      "==========\n",
      "Initial state:-\n",
      "--Days left: 6\n",
      "--State of Field: [1 1 1 1 0]\n",
      "--Current life: 3\n",
      "--Type of Weather: Clear\n",
      "\n",
      "62\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.37\n",
      "Reward?: 1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 5\n",
      "--State of Field: [1 1 0 1 1]\n",
      "--Current life: 4\n",
      "--Type of Weather: Clear\n",
      "\n",
      "64\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.95\n",
      "Reward?: 1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 4\n",
      "--State of Field: [1 1 0 0 1]\n",
      "--Current life: 5\n",
      "--Type of Weather: Clear\n",
      "\n",
      "52\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.73\n",
      "Reward?: -2\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 3\n",
      "--State of Field: [0 0 1 0 0]\n",
      "--Current life: 3\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "21\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.60\n",
      "Reward?: 1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 2\n",
      "--State of Field: [1 1 0 1 1]\n",
      "--Current life: 4\n",
      "--Type of Weather: Clear\n",
      "\n",
      "64\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.16\n",
      "Reward?: -2\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 1\n",
      "--State of Field: [1 0 0 0 0]\n",
      "--Current life: 2\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "19\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.16\n",
      "Reward?: -2\n",
      "is Alive?: False\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 0\n",
      "--State of Field: [1 0 0 1 0]\n",
      "--Current life: 0\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 2\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(f\"Episode #{episode+1}\")\n",
    "    print(\"=\" * 10)\n",
    "\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "\n",
    "    print(\"Initial state:-\")\n",
    "    env.render()\n",
    "    print()\n",
    "\n",
    "    while not done:\n",
    "        enc_state = env.encode(sum(state[\"field_state\"]), state[\"life_points\"], state[\"weather_type\"])\n",
    "        print(enc_state)\n",
    "        action = np.argmax(optimal_policy[enc_state])\n",
    "        print(f\"Action to take: {env.ACTION_DICT[action]}\")\n",
    "        state, reward, done, info = env.step(action)\n",
    "        print(f'Chance to find food: {info[\"chance\"]:.2f}')\n",
    "        print(f\"Reward?: {reward}\")\n",
    "        print(f\"is Alive?: {not done}\")\n",
    "        print()\n",
    "        print(\"Current game state:-\")\n",
    "        env.render()\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20d1d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-2.75 +/- 1.61\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "episode_reward = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        enc_state = env.encode(sum(state[\"field_state\"]), state[\"life_points\"], state[\"weather_type\"])\n",
    "        action = np.argmax(optimal_policy[enc_state])\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "    episode_reward.append(total_reward)\n",
    "\n",
    "print(f\"mean_reward:{np.mean(episode_reward):.2f} +/- {np.std(episode_reward):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2c86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268ac3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MultiInputPolicy', env, exploration_fraction=0.3).learn(total_timesteps=int(2e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c95d07e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #1\n",
      "==========\n",
      "Initial state:-\n",
      "--Days left: 6\n",
      "--State of Field: [1 0 1 1 1]\n",
      "--Current life: 5\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 5\n",
      "--State of Field: [1 0 0 0 0]\n",
      "--Current life: 4\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.73\n",
      "Reward?: 1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 4\n",
      "--State of Field: [0 0 1 0 1]\n",
      "--Current life: 5\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.16\n",
      "Reward?: -2\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 3\n",
      "--State of Field: [1 1 0 0 1]\n",
      "--Current life: 3\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 2\n",
      "--State of Field: [1 1 1 1 0]\n",
      "--Current life: 2\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 1\n",
      "--State of Field: [1 1 1 1 0]\n",
      "--Current life: 1\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.60\n",
      "Reward?: -2\n",
      "is Alive?: False\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 0\n",
      "--State of Field: [0 0 0 1 0]\n",
      "--Current life: 0\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "----------\n",
      "Episode #2\n",
      "==========\n",
      "Initial state:-\n",
      "--Days left: 6\n",
      "--State of Field: [0 1 0 1 0]\n",
      "--Current life: 3\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.95\n",
      "Reward?: 1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 5\n",
      "--State of Field: [1 1 1 1 1]\n",
      "--Current life: 4\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 4\n",
      "--State of Field: [1 1 0 1 0]\n",
      "--Current life: 3\n",
      "--Type of Weather: Clear\n",
      "\n",
      "Action to take: Wait\n",
      "Chance to find food: 0.00\n",
      "Reward?: -1\n",
      "is Alive?: True\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 3\n",
      "--State of Field: [0 0 0 1 0]\n",
      "--Current life: 2\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "Action to take: Forage\n",
      "Chance to find food: 0.16\n",
      "Reward?: -2\n",
      "is Alive?: False\n",
      "\n",
      "Current game state:-\n",
      "--Days left: 2\n",
      "--State of Field: [1 0 1 1 1]\n",
      "--Current life: 0\n",
      "--Type of Weather: Rainy\n",
      "\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 2\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(f\"Episode #{episode+1}\")\n",
    "    print(\"=\" * 10)\n",
    "\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "\n",
    "    print(\"Initial state:-\")\n",
    "    env.render()\n",
    "    print()\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(state)\n",
    "        print(f\"Action to take: {env.ACTION_DICT[action]}\")\n",
    "        state, reward, done, info = env.step(action)\n",
    "        print(f'Chance to find food: {info[\"chance\"]:.2f}')\n",
    "        print(f\"Reward?: {reward}\")\n",
    "        print(f\"is Alive?: {not done}\")\n",
    "        print()\n",
    "        print(\"Current game state:-\")\n",
    "        env.render()\n",
    "        print()\n",
    "\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(num_states):\n",
    "#     field, life_point, weather = env.decode(idx)\n",
    "#     field_state = np.zeros(env.NUM_FIELDS, dtype=int)\n",
    "#     field_state[:field] = 1\n",
    "#     state = {\n",
    "#         \"field_state\": field_state,\n",
    "#         \"life_points\": life_point,\n",
    "#         \"weather_type\": weather\n",
    "#     }\n",
    "\n",
    "#     action, _ = model.predict(state, deterministic=True)\n",
    "#     print(f\"field: {field}/{env.NUM_FIELDS}, life_point: {life_point}, weather: {env.WEATHER_DICT[weather]}:- action: {env.ACTION_DICT[action]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99415888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-2.71 +/- 1.66\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=1000)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c3746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dffa0d8b061e1cee80b43268a62de6d7fbb9b3c81b2fb8e768d3a4c6f15ae987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
